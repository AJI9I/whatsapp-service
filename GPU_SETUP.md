# Настройка GPU для Ollama

## Проверка наличия GPU

У вас обнаружена видеокарта: **NVIDIA GeForce RTX 4060 Laptop GPU** (8 ГБ памяти)

### Шаг 1: Проверка драйверов NVIDIA

Выполните в командной строке:
```cmd
nvidia-smi
```

Если команда работает и показывает информацию о видеокарте - драйверы установлены корректно.

### Шаг 2: Проверка использования GPU в Ollama

Ollama автоматически использует GPU, если он доступен. Проверить, использует ли Ollama GPU:

1. Запустите Ollama сервер
2. Выполните в командной строке:
   ```cmd
   curl http://localhost:11434/api/ps
   ```
3. Если в ответе есть поле `size_vram` - модель загружена в видеопамять GPU

### Шаг 3: Настройка переменных окружения (опционально)

Если Ollama не использует GPU автоматически, можно настроить через переменные окружения:

#### Windows:
1. Откройте "Системные свойства" → "Дополнительно" → "Переменные среды"
2. В разделе "Системные переменные" нажмите "Создать"
3. Добавьте переменную:
   - **Имя**: `OLLAMA_GPU_LAYERS`
   - **Значение**: `99` (использовать максимум слоев для GPU)
4. Перезапустите Ollama сервер

#### Альтернативно через .env файл:

В файле `whatsapp-service/.env` добавьте:
```env
# Использовать все доступные GPU (по умолчанию)
OLLAMA_NUM_GPU=-1

# Или использовать только CPU (если нужно отключить GPU)
# OLLAMA_NUM_GPU=0

# Или использовать конкретное количество GPU
# OLLAMA_NUM_GPU=1
```

### Шаг 4: Перезапуск сервисов

После изменения настроек перезапустите:
1. Ollama сервер
2. WhatsApp сервис (npm start)

### Проверка производительности

После настройки GPU обработка больших моделей (например, `gpt-oss:20b`) должна быть значительно быстрее:

- **Без GPU**: обработка может занимать 3-10+ минут или не завершаться (таймаут)
- **С GPU**: обработка должна завершаться за 30-180 секунд (в зависимости от модели)

### Мониторинг использования GPU

Во время работы Ollama можно отслеживать использование GPU:
```cmd
nvidia-smi -l 1
```

Эта команда обновляет информацию о GPU каждую секунду.

### Решение проблем

Если GPU не используется:

1. **Проверьте версию драйверов**: обновите драйверы NVIDIA до последней версии
2. **Проверьте CUDA Toolkit**: Ollama требует CUDA для работы с GPU
3. **Проверьте логи Ollama**: запустите Ollama в отдельном окне и смотрите сообщения
4. **Проверьте переменные окружения**: убедитесь, что `OLLAMA_GPU_LAYERS` установлена
5. **Перезапустите Ollama сервер**: после изменения настроек обязателен перезапуск

### Текущая конфигурация

- **GPU**: NVIDIA GeForce RTX 4060 Laptop GPU (8 ГБ)
- **Модель**: gpt-oss:20b
- **Таймаут**: 10 минут (600000 мс) для больших моделей
- **Контекст**: 16384 токенов
- **Генерация**: до 16384 токенов

---

*Обновлено: 2025-11-21*



